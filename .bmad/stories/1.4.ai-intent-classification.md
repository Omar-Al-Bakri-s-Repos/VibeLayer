# Story 1.4: AI Intent Classification Engine

## Status: Draft
**Priority:** 2 (Core AI Feature)  
**Depends On:** Stories 1.1, 1.2, 1.3 (needs infrastructure, WebSocket, and transcripts)

## Story Statement
**As a** creator,
**I want** the AI to recognize exciting moments, celebrations, and emotional peaks in my conversation,
**So that** appropriate visual effects can be suggested at the right times.

## Acceptance Criteria
1. ✅ Gemini 2.5 Flash integration classifies intents: celebration, wins, losses, gratitude, hype, romance
2. ✅ Intent confidence scoring with threshold controls for suggestion quality
3. ✅ Context window management prevents duplicate suggestions for similar phrases
4. ✅ Intent classification achieves target accuracy >85% on test dataset
5. ✅ Sensitive content filtering prevents inappropriate auto-suggestions
6. ✅ Agent orchestration via LangGraph coordinates STT → Intent → Suggestion pipeline

## Dev Notes

### Epic Context
This story implements the AI brain that understands conversation context and triggers appropriate effects. It's the intelligence layer that makes VibeLayerAI conversation-aware rather than just keyword-based. This directly feeds Story 1.5 (effect rendering) with suggestions.

### Story Dependencies
- **Depends On:** Stories 1.1, 1.2, 1.3 (infrastructure, WebSocket, STT)
- **Blocks:** Story 1.5 (effects need intent classifications)
- **Parallel Potential:** Can work alongside Story 1.6 (safety controls)

### Technical Architecture

#### AI Pipeline Architecture (from docs/architecture/71-ai-layer-architecture-agent-orchestra.md)
```typescript
// LangGraph Agent Orchestra
TranscriptAgent → IntentAgent → EffectAgent → RankingAgent

interface IntentClassification {
  intent: 'celebration' | 'win' | 'loss' | 'gratitude' | 'hype' | 'romance' | 'neutral';
  confidence: number;
  context: string;
  triggers: string[];
  timestamp: Date;
}

interface AIProcessingPipeline {
  transcript: TranscriptResult;
  intent: IntentClassification;
  suggestions: RankedEffect[];
  latency: LatencyMetrics;
}
```

#### Gemini Integration
- **Model:** Gemini 2.5 Flash (low latency)
- **Context:** 60-second rolling transcript window
- **Temperature:** 0.3 (consistent classification)
- **Max Tokens:** 100 (classification only)

### Implementation Tasks

#### Task 1: Set Up Gemini 2.5 Flash
- [ ] Configure Google AI Platform project
- [ ] Enable Gemini API and set quotas
- [ ] Store API keys in Doppler
- [ ] Install @google/generative-ai SDK
- [ ] Create Gemini service wrapper

#### Task 2: Implement Intent Classification
- [ ] Create intent classification service
- [ ] Define intent taxonomy and examples
- [ ] Build classification prompt template
- [ ] Implement streaming classification
- [ ] Add confidence scoring logic

#### Task 3: Build Context Management
- [ ] Create rolling context window (60 seconds)
- [ ] Implement duplicate detection algorithm
- [ ] Add cooldown periods per intent type
- [ ] Track conversation state and flow
- [ ] Handle context resets on topic changes

#### Task 4: Set Up LangGraph Orchestra
- [ ] Install and configure LangGraph
- [ ] Create TranscriptAgent for processing STT
- [ ] Build IntentAgent for classification
- [ ] Implement EffectAgent for mapping intents
- [ ] Add RankingAgent for prioritization

#### Task 5: Add Sensitive Content Filter
- [ ] Define inappropriate content categories
- [ ] Implement profanity filtering
- [ ] Add violence/harm detection
- [ ] Create bypass for creator preferences
- [ ] Log filtered content for review

#### Task 6: Create Training Dataset
- [ ] Collect sample transcripts for each intent
- [ ] Annotate with correct classifications
- [ ] Build evaluation dataset (1000+ examples)
- [ ] Implement accuracy measurement
- [ ] Create continuous improvement pipeline

#### Task 7: Optimize Classification Speed
- [ ] Implement request batching
- [ ] Add result caching for common phrases
- [ ] Use streaming for faster first token
- [ ] Parallelize multiple classifications
- [ ] Monitor and optimize latency

#### Task 8: Build Suggestion Mapping
- [ ] Map intents to effect categories
- [ ] Create relevance scoring algorithm
- [ ] Implement brand compatibility checks
- [ ] Add creator preference weighting
- [ ] Generate suggestion explanations

### File Locations
- Intent service: `/apps/api-services/src/services/ai/intent/`
- LangGraph config: `/apps/api-services/src/services/ai/orchestra/`
- Gemini integration: `/apps/api-services/src/services/ai/gemini/`
- Training data: `/apps/api-services/src/data/training/`
- Intent models: `/packages/shared-types/src/ai/intent.ts`

### Testing Requirements
- Unit tests for classification logic
- Integration tests with Gemini API
- Accuracy tests on evaluation dataset (>85%)
- Latency benchmarks (<200ms p95)
- Context window management tests
- Sensitive content filtering validation
- LangGraph pipeline tests

### Technical Constraints
- Classification latency <200ms (p95)
- Accuracy >85% on test dataset
- Context window: 60 seconds of transcript
- Cooldown: 30 seconds per intent type
- Max concurrent classifications: 100

## Definition of Done
- [ ] Gemini 2.5 Flash integrated
- [ ] Intent classification working for all 6 types
- [ ] Confidence scoring implemented
- [ ] Context window preventing duplicates
- [ ] Accuracy >85% on test dataset
- [ ] Sensitive content filter active
- [ ] LangGraph pipeline orchestrating agents
- [ ] Latency consistently <200ms
- [ ] Integration with transcript flow
- [ ] Documentation and examples updated